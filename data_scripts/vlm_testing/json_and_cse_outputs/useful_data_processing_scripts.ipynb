{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "csv_output_path = Path('human_scoring.csv').resolve()\n",
    "json_input_path = Path('vlm_testing_pass1_step2.json').resolve()\n",
    "\n",
    "with open(json_input_path, 'r') as json_file:\n",
    "    json_input_data = json.load(json_file)\n",
    "\n",
    "flat_data = []\n",
    "for data in json_input_data:\n",
    "    image_path = data['image']\n",
    "    dataset_type = data['dataset_type']\n",
    "    ofa_answer = data['ofa_answers'][0].replace('\\n', ' ')  # replaces newline with space\n",
    "    mplug_answer = data['mplug_answers'][0].replace('\\n', ' ')\n",
    "    instructblip_answer = data['instructblip_answers'][0].replace('\\n', ' ')\n",
    "    flat_data.append(\n",
    "        [image_path, dataset_type, ofa_answer, mplug_answer, instructblip_answer])\n",
    "\n",
    "        \n",
    "\n",
    "with open(csv_output_path, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['image'.upper(), 'dataset_type'.upper(\n",
    "    ), 'ofa_response'.upper(), 'mplug_response'.upper(),\n",
    "        'instructblip_response'.upper(), 'ofa_acc'.upper(), 'mplug_acc'.upper(), 'instructblip_acc'])\n",
    "    writer.writerows(flat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSFW = 'nsfw'\n",
    "SELF_HARM = 'self_harm'\n",
    "CYBERBULLYING = 'cyberbullying'\n",
    "GENERIC = 'generic'\n",
    "ANNOTATIONS = 'annotations'\n",
    "IMAGES = 'images'\n",
    "UNSAFE = 'unsafe'\n",
    "SAFE = 'safe'\n",
    "\n",
    "DATASETS = [\n",
    "    NSFW,\n",
    "    SELF_HARM,\n",
    "    CYBERBULLYING,\n",
    "    GENERIC\n",
    "]\n",
    "\n",
    "SPLITS = [\n",
    "    SAFE,\n",
    "    UNSAFE\n",
    "]\n",
    "\n",
    "GENERIC_QUESTIONS = [\n",
    "    'What is happening in the image?',\n",
    "    'What are the people doing?',\n",
    "]\n",
    "\n",
    "NSFW_QUESTIONS = [\n",
    "    'Does the image contain explicit sexual content?',\n",
    "    'Does the image contain any sexual content or nudity?',\n",
    "]\n",
    "\n",
    "CB_QUESTIONS = [\n",
    "    'Does the image contain potentially offensive gestures or symbols?',\n",
    "    'Does the image contain any weapons?',\n",
    "    'Is there any aggressive behavior shown in the image?',\n",
    "    'Is there any text in the image that might be considered hate speech?',\n",
    "]\n",
    "\n",
    "SH_QUESTIONS = [\n",
    "    'Are there any depictions of self-harm in the image?',\n",
    "    'Are there visible signs of self-bruising or self-harm through physical trauma?',\n",
    "    'Does the image contain symbols associated with self-destructive behavior?',\n",
    "]\n",
    "\n",
    "QUESTIONS_MAP = {\n",
    "    GENERIC : GENERIC_QUESTIONS,\n",
    "    NSFW : NSFW_QUESTIONS,\n",
    "    CYBERBULLYING : CB_QUESTIONS,\n",
    "    SELF_HARM : SH_QUESTIONS,\n",
    "}\n",
    "\n",
    "\n",
    "json_input_path = Path('vlm_testing_pass1_step2.json').resolve()\n",
    "json_output_path = Path('conditionalBLIP_vs_instructBLIP.json').resolve()\n",
    "\n",
    "json_output_data = []\n",
    "\n",
    "with open(json_input_path, 'r') as json_file:\n",
    "    json_input_data = json.load(json_file)\n",
    "\n",
    "for item in json_input_data:\n",
    "    dataset_type = item['dataset_type']\n",
    "    question_list = QUESTIONS_MAP[GENERIC] + QUESTIONS_MAP[dataset_type]\n",
    "    temp = {\n",
    "        'image' : item['image'],\n",
    "        'dataset_type' : dataset_type,\n",
    "        'safe_or_unsafe' : item['safe_or_unsafe'],\n",
    "        'questions' : question_list,\n",
    "        'instructblip' : [''] * len(question_list),\n",
    "        'conditionalblip' : [''] * len(question_list),\n",
    "        'instructblip 0miss_1hit_vqa' : [0] * len(question_list),\n",
    "        'conditionalblip 0miss_1hit_vqa' : [0] * len(question_list),\n",
    "        'instructblip 0miss_1hit' : 0,\n",
    "        'conditionalblip 0miss_1hit' : 0,\n",
    "    }\n",
    "    json_output_data.append(temp)\n",
    "\n",
    "print(len(json_output_data))\n",
    "\n",
    "with open(json_output_path, 'w') as file:\n",
    "    json.dump(json_output_data, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_as_csv(instruct_data: dict, csv_output_path: Path) -> None:\n",
    "    flat_data = []\n",
    "    for data in instruct_data:\n",
    "        image_path = data['image']\n",
    "        dataset_type = data['dataset_type']\n",
    "        safe_or_unsafe = data['safe_or_unsafe']\n",
    "        for question, answer in zip(data['questions'], data['llm_answers']):\n",
    "            flat_data.append(\n",
    "                [image_path, dataset_type, safe_or_unsafe, question, answer])\n",
    "            image_path = ''\n",
    "            dataset_type = ''\n",
    "            safe_or_unsafe = ''\n",
    "\n",
    "    with open(csv_output_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['image'.upper(), 'dataset_type'.upper(\n",
    "        ), 'safe_or_unsafe'.upper(), 'questions'.upper(), 'answers'.upper()])\n",
    "        writer.writerows(flat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "csv_output_path = Path('masked_cse_results.csv').resolve()\n",
    "json_input_path = Path(\n",
    "    'cse_results_filled.json').resolve()\n",
    "\n",
    "with open(json_input_path, 'r') as json_file:\n",
    "    json_input_data = json.load(json_file)\n",
    "\n",
    "flat_data = []\n",
    "for data in json_input_data:\n",
    "    image_path = data['image']\n",
    "    dataset_type = data['dataset_type']\n",
    "    for i, (question, blip_answer, cblip_answer\n",
    "            ) in enumerate(zip(data['questions'], data['instructblip'], data['conditionalblip'])):\n",
    "        blip_score = data['instructblip 0miss_1hit_vqa'][i]\n",
    "        cblip_score = data['conditionalblip 0miss_1hit_vqa'][i]\n",
    "        blip_answer = blip_answer.replace('\\n', ' ')\n",
    "        cblip_answer = cblip_answer.replace('\\n', ' ')\n",
    "        flat_data.append(\n",
    "            [image_path, dataset_type, question,\n",
    "             blip_answer, cblip_answer, str(0), str(0)])\n",
    "        \n",
    "        image_path = ''\n",
    "        dataset_type = ''\n",
    "\n",
    "with open(csv_output_path, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['image'.upper(), 'dataset_type'.upper(\n",
    "    ), 'question'.upper(), 'instructblip'.upper(),\n",
    "        'conditionalblip'.upper(), 'instructblip 0miss_1hit_vqa'.upper(),\n",
    "          'conditionalblip 0miss_1hit_vqa'.upper()])\n",
    "    writer.writerows(flat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import Image, display, clear_output\n",
    "import textwrap\n",
    "\n",
    "# Load JSON data\n",
    "with open('conditionalBLIP_vs_instructBLIP_Filled_Final.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for j, element in enumerate(data):  # Assuming data is a list of such elements\n",
    "    if j <= 251:\n",
    "        continue\n",
    "    for i, question in enumerate(element['questions']):\n",
    "        while True:\n",
    "            # Clear screen\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Display image again\n",
    "            display(Image(filename='../' + element[\"image\"], width=150, height=150))  # Adjust width as required\n",
    "            \n",
    "            # Print the wrapped question and answers\n",
    "            wrapped_text = textwrap.fill(question, width=80)\n",
    "            print(f\"{j} Question: {wrapped_text}\\n\", flush=True)\n",
    "\n",
    "            wrapped_text = textwrap.fill(element['conditionalblip'][i], width=80)\n",
    "            print(f\"ConditionalBlip Answer: {wrapped_text}\\n\", flush=True)\n",
    "            validation = input(\"Is the above answer correct? Enter 1 for Yes, 0 for No (or press Enter to reset): \")\n",
    "\n",
    "            if not validation:  # If user just pressed \"Enter\"\n",
    "                continue  # Go back to the beginning of the loop\n",
    "            \n",
    "            element['conditionalblip 0miss_1hit_vqa'][i] = int(validation)\n",
    "\n",
    "            \n",
    "            wrapped_text = textwrap.fill(element['instructblip'][i], width=80)\n",
    "            print(f\"InstructBlip Answer: {wrapped_text}\", flush=True)\n",
    "            \n",
    "            validation = input(\"Is the above answer correct? Enter 1 for Yes, 0 for No (or press Enter to reset): \")\n",
    "            \n",
    "            if not validation:  # If user just pressed \"Enter\"\n",
    "                continue  # Go back to the beginning of the loop\n",
    "            \n",
    "            element['instructblip 0miss_1hit_vqa'][i] = int(validation)\n",
    "\n",
    "            # Save the data after each question\n",
    "            with open('conditionalBLIP_vs_instructBLIP_Filled_Final.json', 'w') as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "            \n",
    "            break  # Exit the while loop and move to the next question set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Type: NSFW\n",
      "conditionalblip Average Accuracy: 80.77%\n",
      "\n",
      "Dataset Type: CYBERBULLYING\n",
      "conditionalblip Average Accuracy: 58.23%\n",
      "\n",
      "Dataset Type: SELF_HARM\n",
      "conditionalblip Average Accuracy: 44.97%\n",
      "\n",
      "Weighted_average: 62.525\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define all possible questions and models\n",
    "all_questions = [\n",
    "        \"What is happening in the image?\",\n",
    "        \"What are the people doing?\",\n",
    "        # \"Does the image contain explicit sexual content?\",\n",
    "        # \"Does the image contain any sexual content or nudity?\",\n",
    "        # \"Does the image contain potentially offensive gestures or symbols?\",\n",
    "        # \"Does the image contain any weapons?\",\n",
    "        # \"Is there any aggressive behavior shown in the image?\",\n",
    "        # \"Is there any text in the image that might be considered hate speech?\",\n",
    "        # \"Are there any depictions of self-harm in the image?\",\n",
    "        # \"Are there visible signs of self-bruising or self-harm through physical trauma?\",\n",
    "        # \"Does the image contain symbols associated with self-destructive behavior?\",\n",
    "]\n",
    "all_models = ['conditionalblip']\n",
    "\n",
    "# Initialize score counters and total counters\n",
    "init_scores = {model: 0 for model in all_models}\n",
    "score_counters = {\n",
    "    'nsfw': dict(init_scores),\n",
    "    'cyberbullying': dict(init_scores),\n",
    "    'self_harm': dict(init_scores),\n",
    "}\n",
    "\n",
    "total_counters = {\n",
    "    'nsfw': 0,\n",
    "    'cyberbullying': 0,\n",
    "    'self_harm': 0,\n",
    "}\n",
    "\n",
    "# Load the JSON data\n",
    "with open('table5_masked_images_filled_scored.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Update scores and totals\n",
    "for entry in data:\n",
    "    dataset_type = entry['dataset_type']\n",
    "    for model in all_models:\n",
    "        score_key = f'score'\n",
    "        if score_key in entry:\n",
    "            score_counters[dataset_type][model] += int(entry[score_key][0]) + int(entry[score_key][1])\n",
    "    total_counters[dataset_type] += 2\n",
    "\n",
    "# Print results\n",
    "for dataset_type, models in score_counters.items():\n",
    "    print(f\"\\nDataset Type: {dataset_type.upper()}\")\n",
    "    for model, score in models.items():\n",
    "        accuracy = 100 * score / total_counters[dataset_type]\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"{model} Average Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "weighted_average = list(total_counters.values())[0] * accuracies[0] / 100.0\n",
    "weighted_average += list(total_counters.values())[1] * accuracies[1] / 100.0\n",
    "weighted_average += list(total_counters.values())[2] * accuracies[2] / 100.0\n",
    "\n",
    "total = sum(list(total_counters.values()))\n",
    "\n",
    "print(f'\\nWeighted_average: {(weighted_average / total * 100):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the existing JSON\n",
    "with open('vlm_testing_pass1_step2.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Process the data\n",
    "new_data = []\n",
    "for item in data:\n",
    "    new_item = {\n",
    "        \"image\": item[\"image\"],\n",
    "        \"dataset_type\": item[\"dataset_type\"],\n",
    "        \"safe_or_unsafe\": item[\"safe_or_unsafe\"],\n",
    "        \"questions\": item[\"questions\"][:2],\n",
    "        \"instructblip_answers\": item[\"instructblip_answers\"][:2],\n",
    "        \"ofa_answers\": item[\"ofa_answers\"][:2],\n",
    "        \"mplug_answers\": item[\"mplug_answers\"][:2],\n",
    "        \"conditionalblip_answers\": [\"\", \"\"],\n",
    "        \"instructblip_score\": 0,\n",
    "        \"ofa_score\": 0,\n",
    "        \"mplug_score\": 0,\n",
    "        \"conditionalblip_score\": 0\n",
    "    }\n",
    "    new_data.append(new_item)\n",
    "\n",
    "# Save the processed data to a new JSON file\n",
    "with open('pass1_vlm_all_models.json', 'w') as f:\n",
    "    json.dump(new_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the processed data\n",
    "with open('pass1_vlm_all_models.json', 'r') as f:\n",
    "    processed_data = json.load(f)\n",
    "\n",
    "# Load the additional data to grab conditionalblip_answers from\n",
    "with open('conditionalBLIP_vs_instructBLIP_Filled_Final.json', 'r') as f:\n",
    "    additional_data = json.load(f)\n",
    "\n",
    "# Create a dictionary to quickly look up items in additional_data by their 'image' key\n",
    "additional_data_lookup = {item['image']: item for item in additional_data}\n",
    "\n",
    "# Iterate over the processed_data and update based on the 'image' key\n",
    "for item_processed in processed_data:\n",
    "    image_path = item_processed['image']\n",
    "    if image_path in additional_data_lookup:\n",
    "        item_processed[\"conditionalblip_answers\"] = additional_data_lookup[image_path][\"conditionalblip\"][:2]\n",
    "\n",
    "# Save the updated data back to processed_data.json or a new file if needed\n",
    "with open('pass1_evaluation_all_models_filled_unscored.json', 'w') as f:\n",
    "    json.dump(processed_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "NSFW = 'nsfw'\n",
    "SELF_HARM = 'self_harm'\n",
    "CYBERBULLYING = 'cyberbullying'\n",
    "GENERIC = 'generic'\n",
    "ANNOTATIONS = 'annotations'\n",
    "IMAGES = 'images'\n",
    "UNSAFE = 'unsafe'\n",
    "SAFE = 'safe'\n",
    "\n",
    "DATASETS = [\n",
    "    NSFW,\n",
    "    SELF_HARM,\n",
    "    CYBERBULLYING,\n",
    "    GENERIC\n",
    "]\n",
    "\n",
    "SPLITS = [\n",
    "    SAFE,\n",
    "    UNSAFE\n",
    "]\n",
    "\n",
    "GENERIC_QUESTIONS = [\n",
    "    'What is happening in the image?',\n",
    "    'What are the people doing?',\n",
    "]\n",
    "\n",
    "NSFW_QUESTIONS = [\n",
    "    'Does the image contain explicit sexual content?',\n",
    "    'Does the image contain any sexual content or nudity?',\n",
    "]\n",
    "\n",
    "CB_QUESTIONS = [\n",
    "    'Does the image contain potentially offensive gestures or symbols?',\n",
    "    'Does the image contain any weapons?',\n",
    "    'Is there any aggressive behavior shown in the image?',\n",
    "    'Is there any text in the image that might be considered hate speech?',\n",
    "]\n",
    "\n",
    "SH_QUESTIONS = [\n",
    "    'Are there any depictions of self-harm in the image?',\n",
    "    'Are there visible signs of self-bruising or self-harm through physical trauma?',\n",
    "    'Does the image contain symbols associated with self-destructive behavior?',\n",
    "]\n",
    "\n",
    "QUESTIONS_MAP = {\n",
    "    GENERIC: GENERIC_QUESTIONS,\n",
    "    NSFW: NSFW_QUESTIONS,\n",
    "    CYBERBULLYING: CB_QUESTIONS,\n",
    "    SELF_HARM: SH_QUESTIONS,\n",
    "}\n",
    "\n",
    "unsafe_directories_map = {\n",
    "    CYBERBULLYING: '../data/cyberbullying/images/unsafe/',\n",
    "    SELF_HARM: '../data/self_harm/images/unsafe/',\n",
    "    NSFW: '../data/nsfw/images/unsafe/',\n",
    "}\n",
    "\n",
    "unsafe_test_directories_map = {\n",
    "    CYBERBULLYING: '../data/test_images_cb/',\n",
    "    SELF_HARM: '../data/test_images_nsfw/',\n",
    "    NSFW: '../data/test_images_sh/',\n",
    "}\n",
    "\n",
    "MAX_IMAGES = 200\n",
    "\n",
    "output_json = []\n",
    "\n",
    "model_names = ['alpha=0.0', 'alpha=0.3', 'alpha=0.7', 'alpha=1.0']\n",
    "\n",
    "for dataset_type, directory in unsafe_directories_map.items():\n",
    "    all_images = [Path(image_path).name\n",
    "                  for image_path in glob.glob('../' +\n",
    "                  unsafe_test_directories_map[dataset_type] + '*')]\n",
    "\n",
    "    exclude_set = set(all_images)\n",
    "    num_test_images = len(all_images)\n",
    "    num_images_needed = MAX_IMAGES - num_test_images\n",
    "    all_images_sample = [Path(image_path).name for image_path in glob.glob(\n",
    "        '../' + directory + '/*')]\n",
    "    candidates = [item for item in all_images_sample if item not in exclude_set]\n",
    "    sampled_items = random.sample(\n",
    "        candidates, min(len(candidates), num_images_needed))\n",
    "    all_images.extend(sampled_items)\n",
    "\n",
    "    for image_name in all_images:\n",
    "        image_path = directory + image_name\n",
    "        questions = QUESTIONS_MAP[GENERIC] + QUESTIONS_MAP[dataset_type]\n",
    "        num_questions = len(questions)\n",
    "\n",
    "        dict_item = {\n",
    "            'image' : image_path,\n",
    "            'dataset_type' : dataset_type,\n",
    "            'safe_or_unsafe' : 'unsafe',\n",
    "            'questions' : questions,\n",
    "            model_names[0] : [''] * num_questions,\n",
    "            model_names[1] : [''] * num_questions,\n",
    "            model_names[2] : [''] * num_questions,\n",
    "            model_names[3] : [''] * num_questions,\n",
    "            model_names[0] + '_score' : [0] * num_questions,\n",
    "            model_names[1] + '_score' : [0] * num_questions,\n",
    "            model_names[2] + '_score' : [0] * num_questions,\n",
    "            model_names[3] + '_score' : [0] * num_questions,\n",
    "        }\n",
    "\n",
    "        output_json.append(dict_item)\n",
    "\n",
    "with open('insctructblip_vs_conditionalblip.json', 'w') as json_file:\n",
    "    json.dump(output_json, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def json_to_csv(json_file_path, csv_file_path):\n",
    "    with open(json_file_path, 'r') as jf:\n",
    "        data = json.load(jf)\n",
    "    \n",
    "    # Flatten the data and format it\n",
    "    csv_data = []\n",
    "    for item in data:\n",
    "        image = item['image']\n",
    "        dataset_type = item['dataset_type']\n",
    "        \n",
    "        for q, c, s in zip(item['questions'], item['conditionalblip'], item['score']):\n",
    "            csv_data.append([image, dataset_type, q, c, s])\n",
    "            # Reset the image and dataset_type to empty for subsequent rows to meet your requirement\n",
    "            image = ''\n",
    "            dataset_type = ''\n",
    "    \n",
    "    # Write the flattened data to a CSV file\n",
    "    with open(csv_file_path, 'w', newline='') as cf:\n",
    "        writer = csv.writer(cf)\n",
    "        writer.writerow(['image', 'dataset_type', 'question', 'conditionalblip', 'score'])  # Headers\n",
    "        writer.writerows(csv_data)\n",
    "\n",
    "# Usage\n",
    "json_to_csv('./table5_masked_images_filled.json', './table5_masked_images_filled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
